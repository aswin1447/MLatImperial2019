{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finetuning_seminar.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ChsiG7y_GD4K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/yandexdataschool/MLatImperial2019/blob/master/07_lab/finetuning_seminar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "yphkUietvqk4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f9K3w4WhvvFK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir /content/.kaggle\n",
        "!cp /content/gdrive/My\\ Drive/kaggle.json /content/.kaggle/\n",
        "!chmod 600 /content/.kaggle/kaggle.json\n",
        "!ls -l /content/.kaggle\n",
        "\n",
        "%env KAGGLE_CONFIG_DIR=/content/.kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AlakcXWpv4-V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions download --force -c dogs-vs-cats\n",
        "!unzip train.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yh_vLM3SvjnY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Using pre-trained model\n",
        "\n",
        "Today we're going to build and fine-tune CNN based on weights pre-trained on ImageNet: the largest image classification dataset as of now.\n",
        "More about imagenet: http://image-net.org/\n",
        "Setup: classify from a set of 1000 classes."
      ]
    },
    {
      "metadata": {
        "id": "_2nU6lBGvjnh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import scipy as sp\n",
        "import scipy.misc\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fIcg3V6UvjoB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# class labels\n",
        "LABELS_URL = 'https://s3.amazonaws.com/outcome-blog/imagenet/labels.json'\n",
        "labels = {int(key):value for (key, value) in requests.get(LABELS_URL).json().items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X4-eIRVpvjoJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(list(labels.items())[:5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ms-IVrLfvjoU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### TorchVision\n",
        "PyTorch has several companion libraries, one of them being [torchvision](https://github.com/pytorch/vision/tree/master/) - it contains a number of popular vision datasets, preprocessing tools and most importantly, [pre-trained models](https://github.com/pytorch/vision/tree/master/torchvision/models).\n",
        "\n",
        "For now, we're going to use torch Inception-v3 module."
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "ZXuARu8_vjoX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We're gonna use the inception-v3 network:\n",
        "![img](https://hackathonprojects.files.wordpress.com/2016/09/googlenet_diagram.png?w=650&h=192)\n",
        "\n",
        "Let's first look at the code here: [url](https://github.com/pytorch/vision/blob/master/torchvision/models/inception.py)"
      ]
    },
    {
      "metadata": {
        "id": "MA86FCdpvjoa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchvision.models.inception import inception_v3\n",
        "\n",
        "model = inception_v3(pretrained=True,      # load existing weights\n",
        "                     transform_input=False, # preprocess input image the same way as in training\n",
        "                    )\n",
        "\n",
        "model.aux_logits = False # don't predict intermediate logits (yellow layers at the bottom)\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bUXPwExUvjom",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from skimage.transform import resize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZOw-Jotlvjou",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Predict class probabilities"
      ]
    },
    {
      "metadata": {
        "id": "rDPaNJZeE0sJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://github.com/yandexdataschool/MLatImperial2019/raw/master/07_lab/sample_images/albatross.jpg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6l5_04ycvjoy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img = resize(plt.imread('albatross.jpg'), (299,299))\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "img = torch.FloatTensor(img.reshape([1, 299, 299, 3]).transpose([0,3,1,2]))\n",
        "\n",
        "probs = torch.nn.functional.softmax(model(img), dim=-1)\n",
        "\n",
        "probs = probs.data.numpy()\n",
        "\n",
        "top_ix = probs.ravel().argsort()[-1:-10:-1]\n",
        "print ('top-10 classes are: \\n [prob : class label]')\n",
        "for l in top_ix:\n",
        "    print ('%.4f :\\t%s' % (probs.ravel()[l], labels[l].split(',')[0]))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6AYyAgo6vjo9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Having fun with pre-trained nets"
      ]
    },
    {
      "metadata": {
        "id": "GqRjQGKEvjo_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget http://cdn.com.do/wp-content/uploads/2017/02/Donal-Trum-Derogar.jpeg -O img.jpg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CCDlJZJuvjpH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img = resize(plt.imread('img.jpg'), (299,299))# / 255.\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "img = torch.FloatTensor(img.reshape([1, 299, 299, 3]).transpose([0,3,1,2]))\n",
        "\n",
        "probs = torch.nn.functional.softmax(model(img), dim=-1)\n",
        "\n",
        "probs = probs.data.numpy()\n",
        "\n",
        "top_ix = probs.ravel().argsort()[-1:-10:-1]\n",
        "print ('top-10 classes are: \\n [prob : class label]')\n",
        "for l in top_ix:\n",
        "    print ('%.4f :\\t%s' % (probs.ravel()[l], labels[l].split(',')[0]))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P95r0oWTvjpN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Grand-quest: Dogs Vs Cats\n",
        "* original competition\n",
        "* https://www.kaggle.com/c/dogs-vs-cats\n",
        "* 25k JPEG images of various size, 2 classes (guess what)\n",
        "\n",
        "### Your main objective\n",
        "* In this seminar your goal is to fine-tune a pre-trained model to distinguish between the two rivaling animals\n",
        "* The first step is to just reuse some network layer as features"
      ]
    },
    {
      "metadata": {
        "id": "xVvOx5-LvjpY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### As before, we will use auxilary function you have seen on Monday"
      ]
    },
    {
      "metadata": {
        "id": "VHIqL1MCvjpa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class Logger:\n",
        "  def __init__(self):\n",
        "    self.train_loss_batch = []\n",
        "    self.train_loss_epoch = []\n",
        "    self.test_loss_batch = []\n",
        "    self.test_loss_epoch = []\n",
        "    self.train_batches_per_epoch = 0\n",
        "    self.test_batches_per_epoch = 0\n",
        "    self.epoch_counter = 0\n",
        "    \n",
        "    self.accuracy = []\n",
        "\n",
        "  def fill_train(self, loss):\n",
        "    self.train_loss_batch.append(loss)\n",
        "    self.train_batches_per_epoch += 1\n",
        "\n",
        "  def fill_test(self, loss):\n",
        "    self.test_loss_batch.append(loss)\n",
        "    self.test_batches_per_epoch += 1\n",
        "    \n",
        "  def fill_accuracy(self, y_true, y_pred):    \n",
        "    self.accuracy.append(accuracy_score(y_true, y_pred))\n",
        "\n",
        "  def finish_epoch(self):\n",
        "    self.train_loss_epoch.append(np.mean(\n",
        "        self.train_loss_batch[-self.train_batches_per_epoch:]\n",
        "    ))\n",
        "    self.test_loss_epoch.append(np.mean(\n",
        "        self.test_loss_batch[-self.test_batches_per_epoch:]\n",
        "    ))\n",
        "    self.train_batches_per_epoch = 0\n",
        "    self.test_batches_per_epoch = 0\n",
        "    \n",
        "    clear_output()\n",
        "  \n",
        "    print(\"epoch #{} \\t train_loss: {:.8} \\t test_loss: {:.8} \\t test_acc: {:.8}\".format(\n",
        "              self.epoch_counter,\n",
        "              self.train_loss_epoch[-1],\n",
        "              self.test_loss_epoch [-1],\n",
        "              self.accuracy[-1]\n",
        "          ))\n",
        "    \n",
        "    self.epoch_counter += 1\n",
        "\n",
        "    plt.figure(figsize=(18, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.plot(self.train_loss_batch, label='train loss')\n",
        "    plt.xlabel('# batch iteration')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.plot(self.train_loss_epoch, label='average train loss')\n",
        "    plt.plot(self.test_loss_epoch , label='average test loss' )\n",
        "    plt.legend()\n",
        "    plt.xlabel('# epoch')\n",
        "    plt.ylabel('loss')\n",
        "    \n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.plot(self.accuracy, label='test acc')\n",
        "    plt.xlabel('# epoch')\n",
        "    plt.ylabel('acc')\n",
        "    plt.legend()    \n",
        "    \n",
        "    plt.show();\n",
        "    \n",
        "    \n",
        "def preprocess_data(X, y):\n",
        "  X_preprocessed = torch.tensor(X)\n",
        "  y_preprocessed = torch.tensor(y)\n",
        "  return X_preprocessed, y_preprocessed\n",
        "\n",
        "\n",
        "def get_batches(X, y, batch_size, shuffle=False):\n",
        "  if shuffle:\n",
        "    shuffle_ids = np.random.permutation(len(X))\n",
        "    X = X[shuffle_ids].copy()\n",
        "    y = y[shuffle_ids].copy()\n",
        "  for i_picture in range(0, len(X), batch_size):\n",
        "    # Get batch and preprocess it:\n",
        "    batch_X = X[i_picture:i_picture + batch_size]\n",
        "    batch_y = y[i_picture:i_picture + batch_size]\n",
        "    \n",
        "    # 'return' the batch (see the link above to\n",
        "    # better understand what 'yield' does)\n",
        "    yield preprocess_data(batch_X, batch_y)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ptWexz6rvjpf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We also introduce new functions, they are very convinient in PyTorch, when you need to work with data, that does not fit in memory but can be easily downloaded in batches, for example, images"
      ]
    },
    {
      "metadata": {
        "id": "ml0fCj3Uvjph",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset \n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UkpczC3Uvjpm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    \"\"\"\n",
        "    This class inherits from pytorch dataset.\n",
        "    It defines, how the data will be downloaded and preprocessed.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, data_paths, transform_X=None):\n",
        "        self.data_paths = data_paths\n",
        "        self.transform_X = transform_X\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        x = Image.open(self.data_paths[index])\n",
        "        if self.transform_X:\n",
        "            x = self.transform_X(x)\n",
        "        y = \"cat\" in self.data_paths[index]\n",
        "        return x, np.float32(y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_paths)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DYzBrwAvvjps",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define path to folder with images\n",
        "train_paths = [\"./train/\" + name for name in os.listdir(\"train/\")]\n",
        "\n",
        "# Here I split val/train half and half\n",
        "val_paths = train_paths[:12500]\n",
        "train_paths= train_paths[12500:]\n",
        "\n",
        "len(val_paths), len(train_paths), np.sum([\"cat\" in path for path in val_paths]),\\\n",
        "                                  np.sum([\"cat\" in path for path in train_paths])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9C3j3P_Hvjpy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Since we are going to use pretrained model we need **TO MAKE SURE** that we preprocess the data in the same way, it was done during training.\n",
        "\n",
        "In this case, we need to\n",
        "\n",
        "- Resize the image\n",
        "- Normalise it"
      ]
    },
    {
      "metadata": {
        "id": "6PuZzFSTvjp0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "means = np.array((0.485, 0.456, 0.406))\n",
        "stds = np.array((0.229, 0.224, 0.225))\n",
        "\n",
        "transform_X = transforms.Compose([\n",
        "    transforms.Resize((299, 299)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(means, stds),\n",
        "])\n",
        "\n",
        "\n",
        "subset_of_train = 5000\n",
        "\n",
        "train_dataset = MyDataset(train_paths[:subset_of_train], transform_X=transform_X)\n",
        "\n",
        "train_batch_gen = torch.utils.data.DataLoader(train_dataset, \n",
        "                                              batch_size=256,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=10)\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((299, 299)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(means, stds),\n",
        "])\n",
        "\n",
        "subset_of_val = 1000\n",
        "\n",
        "val_dataset = MyDataset(val_paths[:subset_of_val], transform_X=transform_test)\n",
        "\n",
        "val_batch_gen = torch.utils.data.DataLoader(val_dataset, \n",
        "                                            batch_size=256,\n",
        "                                            shuffle=False,\n",
        "                                            num_workers=10)\n",
        "\n",
        "# If you do not understand what is going on, run the loop below and see the output shapes\n",
        "# for (x_batch, y_batch) in train_batch_gen:\n",
        "\n",
        "#     print('X:', type(x_batch), x_batch.shape)\n",
        "#     print('y:', type(y_batch), y_batch.shape)\n",
        "#     break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D55v_EjNvjp4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Task 1. Use standard sklearn to train"
      ]
    },
    {
      "metadata": {
        "id": "p6Xccduovjp6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "So now, we will use loaded above Inception model and get its output. Since we do not want to have classifcation as in ImageNet, we substitute the last layer with identity."
      ]
    },
    {
      "metadata": {
        "id": "TRnlzWdlvjp7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-QvmUzzpvjp_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "# create layer that returns unchanged input\n",
        "class Identity(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Identity, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pY58aX8_vjqE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "model.fc = Identity()\n",
        "model.to(device)\n",
        "new_X_train, new_y_train = [], []\n",
        "for (X_batch, y_batch) in train_batch_gen:\n",
        "    with torch.no_grad():\n",
        "        new_X_train.extend(model(X_batch.to(device)).detach().cpu().numpy())\n",
        "        new_y_train.extend(y_batch.detach().cpu().numpy())\n",
        "\n",
        "new_X_train = np.array(new_X_train)\n",
        "new_y_train = np.array(new_y_train)        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rh5Nj4cbvjqH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "new_X_test, new_y_test = [], []\n",
        "for (X_batch, y_batch) in val_batch_gen:\n",
        "    with torch.no_grad():\n",
        "        new_X_test.extend(model(X_batch.to(device)).detach().cpu().numpy())\n",
        "        new_y_test.extend(y_batch.detach().cpu().numpy())\n",
        "        \n",
        "new_X_test = np.array(new_X_test)\n",
        "new_y_test = np.array(new_y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4ihYUkp9vjqK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "<YOUR CODE> fit and predict accuracy of the classifier of you choice of the new* datasets, defined above"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D2IzWz2MvjqV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Task 2. Use just predicticted outputs of pretrained net as input for NN "
      ]
    },
    {
      "metadata": {
        "id": "n0uDHuXCvjqW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To explore the power of this technique, let just take just one batch - 256 images as training data."
      ]
    },
    {
      "metadata": {
        "id": "jub3JsZ6vjqX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "subset_of_train = 256\n",
        "train_dataset = MyDataset(train_paths[:subset_of_train], transform_X=transform_X)\n",
        "train_batch_gen = torch.utils.data.DataLoader(train_dataset, \n",
        "                                              batch_size=256,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=10)\n",
        "\n",
        "model.eval()\n",
        "model.fc = Identity()\n",
        "model.to(device)\n",
        "new_X_train, new_y_train = [], []\n",
        "for (X_batch, y_batch) in train_batch_gen:\n",
        "    with torch.no_grad():\n",
        "        new_X_train.extend(model(X_batch.to(device)).detach().cpu().numpy())\n",
        "        new_y_train.extend(y_batch.detach().cpu().numpy())\n",
        "\n",
        "new_X_train = np.array(new_X_train)\n",
        "new_y_train = np.array(new_y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "img0zJLMvjqa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we define our new NN head"
      ]
    },
    {
      "metadata": {
        "id": "m0fl0SlWvjqb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NetHead(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.head = nn.Sequential(\n",
        "            <YOUR CODE>\n",
        "        )\n",
        "        \n",
        "    def forward(self, input):\n",
        "        return self.head(input)\n",
        "\n",
        "tn = NetHead().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "72rjBXZevjqh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And train it as before we did before"
      ]
    },
    {
      "metadata": {
        "id": "hA4bgaOEvjqj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss_function = torch.nn.BCELoss()\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.Adam(tn.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TSoH5GtZzvgY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "logger = Logger()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oM22EA3Svjqm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 20\n",
        "\n",
        "\n",
        "for i_epoch in range(n_epochs):\n",
        "    tn.train()\n",
        "    for (X_batch, y_batch) in get_batches(new_X_train, new_y_train, batch_size=128):\n",
        "        \n",
        "        loss = loss_function(tn(X_batch.to(device)), y_batch.view(-1,1).to(device))\n",
        "\n",
        "        tn.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        logger.fill_train(loss.item())\n",
        "  \n",
        "    tn.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    for (X_batch, y_batch) in get_batches(new_X_test, new_y_test, batch_size=256):\n",
        "        with torch.no_grad():\n",
        "            y_net = tn(X_batch.to(device))\n",
        "            loss = loss_function(y_net, y_batch.view(-1,1).cuda(0))\n",
        "            y_pred.extend(y_net.detach().cpu().numpy())\n",
        "            y_true.extend(y_batch.view(-1,1).detach().cpu().numpy())\n",
        "            logger.fill_test(loss.item())\n",
        "    logger.fill_accuracy(np.array(y_true), np.array(y_pred) > 0.5)\n",
        "    logger.finish_epoch()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A_C0AfPzvjqq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Impressive right?"
      ]
    },
    {
      "metadata": {
        "id": "i_kBhL3gvjqr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Task 3. Use just predicticted pretrained net to define new model"
      ]
    },
    {
      "metadata": {
        "id": "qfO6hw-2vjqu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class TransferredNet(nn.Module):\n",
        "    def __init__(self, pretrained_model):\n",
        "        super().__init__()\n",
        "        self.pretrained_model = <YOUR CODE>\n",
        "        self.pretrained_model.fc = Identity()\n",
        "        \n",
        "        self.head = nn.Sequential(\n",
        "            <YOUR CODE>\n",
        "        )\n",
        "        \n",
        "    def forward(self, input):\n",
        "        return <YOUR CODE>\n",
        "\n",
        "tn = TransferredNet(model).to(device)\n",
        "\n",
        "for param in tn.pretrained_model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Easqwopdvjqy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss_function = torch.nn.BCELoss()\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Look here we only provide optimiser parameters, we really want to optimise (ie propogate gradient)\n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, tn.parameters()), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r-z0RHIevjq0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "logger = Logger()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EKvy2jEAvjq2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 10\n",
        "\n",
        "for i_epoch in range(n_epochs):\n",
        "    tn.train()\n",
        "    tn.pretrained_model.eval()\n",
        "    print(\"Train:\" + \"-\"*30 + \"->\\n\")\n",
        "    for (X_batch, y_batch) in train_batch_gen:\n",
        "        \n",
        "        loss = loss_function(tn(X_batch.to(device)), y_batch.view(-1,1).to(device))\n",
        "\n",
        "        tn.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        logger.fill_train(loss.item())\n",
        "  \n",
        "    tn.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    print(\"Eval:\" + \"-\"*30 + \"->\\n\")\n",
        "    for (X_batch, y_batch) in val_batch_gen:\n",
        "        with torch.no_grad():\n",
        "            y_net = tn(X_batch.to(device))\n",
        "            loss = loss_function(y_net, y_batch.view(-1,1).to(device))\n",
        "            y_pred.extend(y_net.detach().cpu().numpy())\n",
        "            y_true.extend(y_batch.view(-1,1).detach().cpu().numpy())\n",
        "            logger.fill_test(loss.item())\n",
        "    logger.fill_accuracy(np.array(y_true), np.array(y_pred) > 0.5)\n",
        "    logger.finish_epoch()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HGA_NNhi5zEc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5UWpfAaK55dO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Before next step, it s a good idea to save weights, since the procedure is very unstable."
      ]
    },
    {
      "metadata": {
        "id": "IYA6z2_Nvjq4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#torch.save(tn, \"trained_head.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w_LC4Q411T68",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "OK, now, to get even better result, one can finetune the body network as well.\n",
        "This procedure is unstable and requite very small learning rate and simple optimisation algo.\n",
        "Also, since the body is huge, we can only work with small batch size to fit in GPU."
      ]
    },
    {
      "metadata": {
        "id": "nCv6lBy1vjrO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_batch_gen = torch.utils.data.DataLoader(train_dataset, \n",
        "                                              batch_size=32,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=10)\n",
        "\n",
        "\n",
        "<YOUR CODE> - enable backprop throught whole net \n",
        "\n",
        "\n",
        "loss_function = torch.nn.BCELoss()\n",
        "learning_rate = 0.001\n",
        "\n",
        "optimizer = torch.optim.SGD(<YOUR CODE>, lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YW8oz3cC1rg4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 10\n",
        "\n",
        "for i_epoch in range(n_epochs):\n",
        "    tn.train()\n",
        "    # tn.pretrained_model.eval() ??\n",
        "    print(\"Train:\" + \"-\"*30 + \"->\\n\")\n",
        "    for (X_batch, y_batch) in train_batch_gen:\n",
        "        \n",
        "        loss = loss_function(tn(X_batch.to(device)), y_batch.view(-1,1).to(device))\n",
        "\n",
        "        tn.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        logger.fill_train(loss.item())\n",
        "  \n",
        "    tn.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    print(\"Eval:\" + \"-\"*30 + \"->\\n\")\n",
        "    for (X_batch, y_batch) in val_batch_gen:\n",
        "        with torch.no_grad():\n",
        "            y_net = tn(X_batch.to(device))\n",
        "            loss = loss_function(y_net, y_batch.view(-1,1).to(device))\n",
        "            y_pred.extend(y_net.detach().cpu().numpy())\n",
        "            y_true.extend(y_batch.view(-1,1).detach().cpu().numpy())\n",
        "            logger.fill_test(loss.item())\n",
        "    logger.fill_accuracy(np.array(y_true), np.array(y_pred) > 0.5)\n",
        "    logger.finish_epoch()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uxo30sO1vjrb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Bonus: #deepdream\n",
        "\n",
        "https://twitter.com/search?q=%23deepdream&src=typd\n",
        "\n",
        "Code is heavily based on https://github.com/thesemicolonguy/deep-dream-pytorch\n",
        "\n",
        "Original blogpost where more ideas can be taken from: https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html"
      ]
    },
    {
      "metadata": {
        "id": "eIpMeyQSvjrc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageFilter, ImageChops\n",
        "from torchvision import transforms\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yfhk3CVu-Muk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchvision.models.vgg import vgg16\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(means, stds)\n",
        "    ])\n",
        "\n",
        "def deprocess(image):\n",
        "    return image * torch.Tensor(stds).to(device)  + torch.Tensor(means).to(device)\n",
        "  \n",
        "  \n",
        "vgg = vgg16(pretrained=True).to(device).eval()\n",
        "print(vgg)\n",
        "modulelist = list(vgg.features.modules())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gISWoAKE-MkA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dd_helper(image, layer, iterations, lr):        \n",
        "    \n",
        "    input = preprocess(image).unsqueeze(0).to(device)\n",
        "    input.requires_grad = True\n",
        "    vgg.zero_grad()\n",
        "    for i in range(iterations):\n",
        "#         print('Iteration: ', i)\n",
        "        out = input\n",
        "        for j in range(layer):\n",
        "            out = modulelist[j+1](out)\n",
        "        loss = out.norm()\n",
        "        loss.backward()\n",
        "        input.data = input.data + lr * input.grad.data\n",
        "    \n",
        "    input = input.data.squeeze()\n",
        "    input.transpose_(0,1)\n",
        "    input.transpose_(1,2)\n",
        "    input = torch.clamp(deprocess(input.detach()), 0, 1)\n",
        "    im = Image.fromarray(np.uint8(input.cpu().numpy()*255))\n",
        "    return im\n",
        "  \n",
        "  \n",
        "def deep_dream_vgg(image, layer, iterations, lr, octave_scale, num_octaves):\n",
        "    \n",
        "    if num_octaves>0:\n",
        "        image1 = image.filter(ImageFilter.GaussianBlur(2))\n",
        "        if(image1.size[0]/octave_scale < 1 or image1.size[1]/octave_scale<1):\n",
        "            size = image1.size\n",
        "        else:\n",
        "            size = (int(image1.size[0]/octave_scale), int(image1.size[1]/octave_scale))\n",
        "            \n",
        "        image1 = image1.resize(size,Image.ANTIALIAS)\n",
        "        image1 = deep_dream_vgg(image1, layer, iterations, lr, octave_scale, num_octaves-1)\n",
        "        size = (image.size[0], image.size[1])\n",
        "        image1 = image1.resize(size,Image.ANTIALIAS)\n",
        "        image = ImageChops.blend(image, image1, 0.6)\n",
        "#     print(\"-------------- Recursive level: \", num_octaves, '--------------')\n",
        "    img_result = dd_helper(image, layer, iterations, lr)\n",
        "    img_result = img_result.resize(image.size)\n",
        "    plt.imshow(img_result)\n",
        "    return img_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I0199BrJ-MT8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ld8sf4vYvjrj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## need to adjust branching of inception to match size"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dIlhopYzCqcT",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img = Image.open('img.jpg')\n",
        "#img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vpO_4BUGC3nd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output = deep_dream_vgg(img, 5, 10, 0.3, 2, 20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ablhkhHnCpcl",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output = deep_dream_vgg(img, 26, 8, 0.1, 2, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}